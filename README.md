# route53-backup
Back up Route 53 DNS records to S3.

## About
This is a fork from jacobfgrant/route53-lambda-backup.
The primary intent is to ready the script for use for larger Route53 accounts because the 15 minute time limit imposed by AWS Lambda prevents full execution on large accounts due to AWS API interaction limits.
To get around this, we can use AWS Elastic Container Service (ECS) or EKS. Other methods of execution, including Lambda, are still available using this script.

## Setup
This script can be run either as a container on ECS or EKS, a scheduled AWS Lambda function, or as a bare Python script or Docker container via cron job on EC2 or your own hardware. 

### As a container

#### On ECS or EKS
_Recommended for large Route53 deployments_

The easiest mechanism is to use the [Docker Image](https://hub.docker.com/repository/docker/jrokeach/route53-backup). You can load this into ECS by specifying the docker image `jrokeach/route53-backup`.
Set the environment variables `S3_BUCKET_NAME` AND `S3_BUCKET_REGION` according to your needs.
Ensure that your task has permissions to write to your S3 bucket and read from Route53.

#### Docker
Alternatively, to install to a docker container locally, run:
```bash
docker pull jrokeach/route53-backup
```
To then run the container, run:
```bash
docker run \
> -e S3_BUCKET_NAME="<S3BUCKET>" \
> -e S3_BUCKET_REGION="<S3BUCKETREGION>" \
> -e AWS_ACCESS_KEY_ID="<AWSACCESSKEYID>" \
> -e AWS_SECRET_ACCESS_KEY="<AWSSECRETACCESSKEY>" \
> jrokeach/route53-backup
```
The access key must belong to a user with permissions to write to your S3 bucket and read from Route53.

### As a lambda function
_Recommended for small Route53 deployments_

Upload the script to AWS Lambda, set the `S3_BUCKET_NAME` and `S3_BUCKET_REGION` environmental variables, set up an IAM role (with Route 53 read-only and S3 read-write permissions), and set a schedule.

### As a Python script
Alternatively, you can set the script to run using cron on an EC2 instance or your own computing environment with the appropriate IAM role permissions. Don't forget to add the proper Python 3 shebang and set the `s3_bucket_name` and `s3_bucket_region` variables in the file when doing so.

## Restoring Backups
Backups generated by this script are uploaded as csv and json files to the specified AWS S3 bucket. They can be restored using AWS provided tools, including the AWS CLI, or using the route53-transfer module. The code and documentation for this module, including how to restore the Route 53 DNS record csv backups, can be found [here](https://github.com/RisingOak/route53-transfer).